
#2주차

##AI 서비스 테스트

datadog의 llm observability로 AI 서비스의 관측성 향상을 연습해보았습니다.

기본적으로 일회성 질문, 답변을 해주는 InvokeModel method 는 자동으로 trace가 잡혔지만 
제가 원하던 지식기반으로 증강시키는 RAG방식의 retriveAndGeneration method는 잡히지않아 수동으로 datadog tarce 라이브러리로 span을 심어줘야할 것 같습니다

span도 종류가 많았지만 retrival span을 심어주는 것이 제가 사용하고 싶은 RAG방식에 걸맞는 방식인 것 같습니다

```
from ddtrace.llmobs.decorators import retrieval

@retrieval
def get_relevant_docs(question):
    context_documents = ... # user application logic
    LLMObs.annotate(
        input_data=question,
        output_data = [ {"id": doc.id, "score": doc.score, "text": doc.text, "name": doc.name} for doc in context_documents  ]
    )
    return 
```
출처 : 
- https://docs.datadoghq.com/ko/llm_observability/terms/#retrieval-span
- https://docs.datadoghq.com/ko/llm_observability/setup/sdk/python/#retrieval-span
- 
##메타데이터

1주차에 지식기반 DB에 넣은 데이터들이 서로 섞여서 제대로된 답변을 못받았었습니다.
메타데이터를 json 형식으로 작성해서 데이터를 분리 및 카테고리화 시킬 수 있는 방법을 알았습니다.

특정 데이터에 대한 메타데이터는 '데이터파일의 이름.metadata.json' 으로 명칭하는 방법으로 설정합니다.

카테고리의 기준은 팀회의로 결정해야 할 것 같아 아직 보류중입니다.

예시 : 
```
김영훈.md.metadata.json
{
  "metadataAttributes": {
    "id": number, 
    "gender": string,
    "age": number,
    "idealType": string
  }
}
```
##2주차 간이 회의

각자 현황 공유 및 서비스 방향성에 대한 토론진행
이지원 팀장님의 기획 가설 검증을 위한 인터뷰결과 공유받음 

ai 서비스에서 메타데이터를 활용해서 각 정보를 격리 시키는 방법을 언급



